# üå± OpenLLM Monitor - Complete Seed Data Guide

Welcome to the comprehensive seed data system for OpenLLM Monitor! This guide covers everything you need to create impressive demo data that showcases all system capabilities.

## üéØ Quick Start Options

### 1. **Simple Seed Data** (Recommended for first-time users)

```powershell
# Windows PowerShell
cd "d:\OpenLLM Monitor\scripts"
.\generate-seed-data.ps1
```

### 2. **Advanced Configurable Seed Data**

```powershell
# Default configuration
node seed-data-advanced.js

# Development scenario (lighter data)
node seed-data-advanced.js --scenario=dev

# High-volume production simulation
node seed-data-advanced.js --scenario=production

# OpenAI-focused dataset
node seed-data-advanced.js --scenario=openai

# Local models focus (Ollama)
node seed-data-advanced.js --scenario=local
```

## üìä What You Get

### **Simple Seed Data** (`seed-data.js`)

- ‚úÖ **30 days** of realistic LLM requests
- ‚úÖ **1,000+ requests** across all providers
- ‚úÖ **7 diverse use cases** with realistic prompts/responses
- ‚úÖ **Error patterns** and retry logic
- ‚úÖ **Cost calculations** based on real pricing
- ‚úÖ **Streaming requests** simulation
- ‚úÖ **Multi-user activity** patterns

### **Advanced Seed Data** (`seed-data-advanced.js`)

- ‚úÖ **Configurable scenarios** for different demo needs
- ‚úÖ **Custom data volumes** and timeframes
- ‚úÖ **Provider distribution control**
- ‚úÖ **Error rate customization**
- ‚úÖ **User behavior simulation**
- ‚úÖ **Realistic usage patterns**

## üé™ Use Cases Covered

### 1. **Code Generation** (30% of requests)

**Sample Prompts:**

- "Write a Python function to calculate Fibonacci sequence"
- "Create a REST API endpoint for user authentication"
- "Generate TypeScript interfaces for user management"

**Realistic Responses:**

- Complete code examples with explanations
- Best practices and error handling
- Multiple language implementations

### 2. **Data Analysis** (20% of requests)

**Sample Prompts:**

- "Analyze quarterly sales trends and provide insights"
- "What KPIs should I track for my SaaS business?"
- "How do I calculate customer churn rate?"

**Realistic Responses:**

- Strategic recommendations with metrics
- Statistical analysis explanations
- Business intelligence insights

### 3. **Customer Support** (15% of requests)

**Sample Prompts:**

- "How do I reset my password without email access?"
- "My subscription was charged twice this month"
- "The app crashes when uploading large files"

**Realistic Responses:**

- Empathetic, solution-focused responses
- Step-by-step troubleshooting guides
- Proactive follow-up suggestions

### 4. **Creative Writing** (10% of requests)

**Sample Prompts:**

- "Write marketing copy for sustainable fashion brand"
- "Create engaging social media captions for travel photos"
- "Draft email newsletter for local bakery"

**Realistic Responses:**

- Compelling, audience-targeted content
- Brand-appropriate tone and messaging
- Call-to-action optimization

### 5. **Education** (10% of requests)

**Sample Prompts:**

- "Explain quantum computing in simple terms"
- "What are machine learning fundamentals?"
- "How does photosynthesis work molecularly?"

**Realistic Responses:**

- Clear explanations with analogies
- Structured learning approaches
- Complex concepts made accessible

### 6. **Business Strategy** (10% of requests)

**Sample Prompts:**

- "How should I expand internationally?"
- "What's my go-to-market strategy?"
- "How do I build competitive advantages?"

**Realistic Responses:**

- Strategic frameworks and methodologies
- Implementation roadmaps
- Risk assessment and mitigation

### 7. **Translation** (5% of requests)

**Sample Prompts:**

- "Translate product description to Spanish"
- "Localize marketing campaign for Japan"
- "Convert technical docs to French"

**Realistic Responses:**

- Culturally appropriate translations
- Localization recommendations
- Context preservation

## üè¢ Provider Coverage

### **OpenAI** (45% of requests)

- **Models:** GPT-4, GPT-4-Turbo, GPT-3.5-Turbo variants
- **Strengths:** Code generation, complex reasoning
- **Average Cost:** $0.002-0.06 per 1K tokens
- **Latency:** 800-3000ms

### **Ollama** (25% of requests)

- **Models:** Llama2, CodeLlama, Mistral, Phi3, Gemma
- **Strengths:** Local deployment, privacy, no costs
- **Average Cost:** $0.00 (local models)
- **Latency:** 2000-8000ms (hardware dependent)

### **OpenRouter** (20% of requests)

- **Models:** GPT-4, Claude-2, Llama-2-70B, Mistral-7B
- **Strengths:** Model variety, competitive pricing
- **Average Cost:** $0.0002-0.06 per 1K tokens
- **Latency:** 1200-4500ms

### **Mistral** (10% of requests)

- **Models:** Mistral-Large, Medium, Small, Tiny
- **Strengths:** Multilingual, reasoning, efficiency
- **Average Cost:** $0.00014-0.024 per 1K tokens
- **Latency:** 600-2500ms

## üìà Analytics Features Showcased

### **Real-time Monitoring**

- ‚úÖ Live request tracking dashboard
- ‚úÖ Success/failure rate monitoring
- ‚úÖ Real-time cost accumulation
- ‚úÖ Active user sessions

### **Performance Analytics**

- ‚úÖ Response time distributions
- ‚úÖ Provider latency comparisons
- ‚úÖ Model performance benchmarks
- ‚úÖ Geographic response patterns

### **Cost Intelligence**

- ‚úÖ Per-provider cost breakdown
- ‚úÖ Token usage optimization
- ‚úÖ Cost-per-use case analysis
- ‚úÖ Budget forecasting data

### **Error Analysis**

- ‚úÖ Error type categorization
- ‚úÖ Retry pattern analysis
- ‚úÖ Provider reliability comparison
- ‚úÖ Failure recovery tracking

### **Usage Patterns**

- ‚úÖ Peak hour identification
- ‚úÖ User behavior segmentation
- ‚úÖ Use case distribution
- ‚úÖ Seasonal trend simulation

## üéõÔ∏è Configuration Options

### **Data Volume Control**

```json
{
  "daysBack": 30, // Days of historical data
  "baseVolumeWeekday": 50, // Requests per weekday
  "baseVolumeWeekend": 20, // Requests per weekend
  "volumeVariation": {
    // Daily volume randomization
    "min": -10,
    "max": 30
  }
}
```

### **Provider Distribution**

```json
{
  "providerDistribution": {
    "openai": 0.45, // 45% of requests
    "ollama": 0.25, // 25% of requests
    "openrouter": 0.2, // 20% of requests
    "mistral": 0.1 // 10% of requests
  }
}
```

### **Error Simulation**

```json
{
  "errorRates": {
    "rateLimit": 0.05, // 5% rate limit errors
    "authentication": 0.02, // 2% auth errors
    "timeout": 0.03, // 3% timeout errors
    "modelOverload": 0.02, // 2% overload errors
    "contentPolicy": 0.01 // 1% policy violations
  }
}
```

### **Request Patterns**

```json
{
  "requestPatterns": {
    "streamingProbability": 0.3, // 30% streaming requests
    "retryProbability": 0.08, // 8% requests have retries
    "maxRetries": 3 // Maximum retry attempts
  }
}
```

## üéØ Demo Scenarios

### **Development Environment**

```bash
node seed-data-advanced.js --scenario=dev
```

- 14 days of data
- 20 requests/weekday, 5/weekend
- Perfect for development testing

### **Production Simulation**

```bash
node seed-data-advanced.js --scenario=production
```

- 60 days of data
- 100 requests/weekday, 40/weekend
- High-volume enterprise simulation

### **OpenAI Focus**

```bash
node seed-data-advanced.js --scenario=openai
```

- 80% OpenAI requests
- Showcase premium model capabilities
- Cost optimization demonstrations

### **Local Models Focus**

```bash
node seed-data-advanced.js --scenario=local
```

- 60% Ollama requests
- Privacy-focused deployment
- Cost-saving demonstrations

### **Coding Assistant**

```bash
node seed-data-advanced.js --scenario=coding
```

- 60% code generation requests
- Developer productivity focus
- Technical use case emphasis

## üöÄ Demo Presentation Flow

### **Executive Overview** (5 minutes)

1. **Dashboard Overview** - Total requests, costs, success rates
2. **Provider Comparison** - Performance vs. cost analysis
3. **ROI Metrics** - Cost savings and efficiency gains

### **Technical Deep Dive** (10 minutes)

1. **Real-time Monitoring** - Live request tracking
2. **Error Analysis** - Failure patterns and recovery
3. **Performance Benchmarks** - Latency optimization
4. **API Integration** - Request/response inspection

### **Business Intelligence** (10 minutes)

1. **Usage Analytics** - User behavior patterns
2. **Cost Optimization** - Provider efficiency comparison
3. **Capacity Planning** - Growth trend analysis
4. **Operational Insights** - Peak hour management

### **Advanced Features** (5 minutes)

1. **Streaming Visualization** - Real-time response building
2. **Retry Logic** - Automatic failure recovery
3. **Multi-user Simulation** - Concurrent usage patterns
4. **Geographic Distribution** - Global deployment insights

## üìã Prerequisites Checklist

- ‚úÖ **Node.js 16+** installed
- ‚úÖ **MongoDB** running and accessible
- ‚úÖ **Internet connection** for npm packages
- ‚úÖ **Sufficient disk space** (500MB recommended)
- ‚úÖ **OpenLLM Monitor** application ready to start

## üõ†Ô∏è Troubleshooting

### **Common Issues**

**"MongoDB connection failed"**

```bash
# Check if MongoDB is running
# Update connection string in script
export MONGODB_URI="your-connection-string"
```

**"Out of memory during generation"**

```bash
# Reduce data volume in config
"baseVolumeWeekday": 20  # Instead of 50
"daysBack": 14           # Instead of 30
```

**"npm install fails"**

```bash
# Clear npm cache
npm cache clean --force
# Try with different registry
npm install --registry https://registry.npmjs.org/
```

## üéâ Success Metrics

After running the seed data, you should see:

### **Dashboard Populated With:**

- ‚úÖ 1,000+ realistic LLM requests
- ‚úÖ Multiple provider performance data
- ‚úÖ Comprehensive cost analysis
- ‚úÖ Error patterns and recovery data
- ‚úÖ User activity simulations
- ‚úÖ 30 days of historical trends

### **Demo-Ready Features:**

- ‚úÖ Real-time monitoring capabilities
- ‚úÖ Provider comparison analytics
- ‚úÖ Cost optimization insights
- ‚úÖ Performance benchmarking
- ‚úÖ Error analysis and alerting
- ‚úÖ Usage pattern identification

## üîÑ Customization Guide

### **Adding New Use Cases**

1. Edit `USE_CASES` object in seed script
2. Add realistic prompts and responses
3. Update distribution percentages
4. Test with small dataset first

### **Modifying Provider Mix**

1. Adjust `providerDistribution` weights
2. Add new models to `PROVIDERS` config
3. Update pricing information
4. Validate cost calculations

### **Custom Time Ranges**

1. Modify `daysBack` parameter
2. Adjust `baseVolume` for different periods
3. Consider seasonal patterns
4. Account for business hours

## üìû Support & Resources

### **Getting Help**

- üìñ Read the full documentation
- üêõ Check troubleshooting section
- üí¨ Review configuration examples
- üéØ Try different demo scenarios

### **Best Practices**

- Start with simple seed data first
- Test with small datasets before full generation
- Monitor MongoDB storage usage
- Backup existing data before seeding
- Use appropriate scenario for your demo audience

---

**Ready to create an impressive OpenLLM Monitor demo? Start with the simple seed data and explore the advanced options as needed!**

üöÄ **Quick Start:** `.\generate-seed-data.ps1`  
üéõÔ∏è **Advanced:** `node seed-data-advanced.js --scenario=production`  
üìä **Custom:** Edit `seed-config.json` for your needs
